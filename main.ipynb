{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Employee Attrition Prediction Model\n",
    "\n",
    "The model uses Employee Attrition dataset from Kaggle's and compares the effectiveness between using Logistic Regression, Neural Network, and Random Forest. We start by analyzing the dataset, keeping the significant ones and removing the uncorrelated ones to optimize performance from our models. Then we proceed to parsing, splitting, and normalizing before training our models. Below are explanations to our work and our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Parsing\n",
    "\n",
    "We start with all the data given from the dataset. The raw dataset has 1470 rows and 35 features including Attrition, which is our desired output feature. In terms of data types, there are 26 numerical features and 9 categorical features, ranging from 2 to 6 categories each.\n",
    "\n",
    "The Parse function below takes in a .CSV file, and does the following things:\n",
    "1. drop the constant features (columns_to_drop_1)\n",
    "2. drop the redundant features (columns_to_drop_2)\n",
    "3. split into input and output features\n",
    "4. One-hot encode the categorical columns\n",
    "5. Map the 'Attrition' feature into boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(file_path):\n",
    "    \"\"\"\n",
    "    Parses the CSV file, normalizes numerical data, and one-hot encodes categorical variables.\n",
    "\n",
    "    Parameters:\n",
    "    - file_path: str, path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    - X_processed: pandas DataFrame, processed feature data.\n",
    "    - y_encoded: pandas Series, encoded target variable.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Dropping constant and redundant features\n",
    "    columns_to_drop_1 = ['EmployeeCount', 'Over18', 'StandardHours', 'EmployeeNumber']\n",
    "    columns_to_drop_2 = ['MonthlyIncome', 'TotalWorkingYears', 'YearsInCurrentRole', 'YearsWithCurrManager']\n",
    "    df = df.drop(columns=columns_to_drop_1)\n",
    "    df = df.drop(columns=columns_to_drop_2)\n",
    "\n",
    "    # Separate features and target variable\n",
    "    X = df.drop('Attrition', axis=1)\n",
    "    y = df['Attrition']\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    # One-hot encode categorical variables\n",
    "    X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Doesn't normalize. Leave normalization until after splitting training, validation, and test sets.\n",
    "    \n",
    "    # Encode the target variable\n",
    "    y_encoded = y.map({'Yes': 1, 'No': 0})\n",
    "\n",
    "    return X_encoded, y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the data isn't normalized when parsing. We leave normalization of data to after we split the data into training, validation, and testing sets. This ensures that there are no data leakages, and provides a better evaluation of our models' performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Simple logistic regression**\n",
    "\n",
    "**Prelminaries**\n",
    "\n",
    "1. Load the data\n",
    "2. Extract test data\n",
    "3. Normalize the training data\n",
    "\n",
    "**Simple logistic regression**\n",
    "\n",
    "5. Train simple logistic regression\n",
    "6. Evaluate the models with cross-validation\n",
    "\n",
    "**Regularization**\n",
    "\n",
    "7. LASSO regularized logistic regression\n",
    "8. Choose the best model\n",
    "9. Significant features\n",
    "10. Evaluate the final model with test data\n",
    "\n",
    "**Conclusion**\n",
    "11. Compare and Contrast resulting accuracies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
